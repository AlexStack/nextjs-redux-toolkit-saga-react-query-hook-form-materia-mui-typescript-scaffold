{"type_of":"article","id":1246729,"title":"Using S3 Compatible Storage Solutions with ApostropheCMS","description":"This tutorial details file storage solutions for FileBase, Vultr, Wasabi, and DigitalOcean using S3...","readable_publish_date":"Nov 7","slug":"using-s3-compatible-storage-solutions-with-apostrophecms-40c1","path":"/apostrophecms/using-s3-compatible-storage-solutions-with-apostrophecms-40c1","url":"https://dev.to/apostrophecms/using-s3-compatible-storage-solutions-with-apostrophecms-40c1","comments_count":0,"public_reactions_count":0,"collection_id":null,"published_timestamp":"2022-11-07T17:47:45Z","positive_reactions_count":0,"cover_image":"https://res.cloudinary.com/practicaldev/image/fetch/s--3vtyt6Nh--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/s677c4xsbgpglgt6vf5y.png","social_image":"https://res.cloudinary.com/practicaldev/image/fetch/s--8N65EVPp--/c_imagga_scale,f_auto,fl_progressive,h_500,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/s677c4xsbgpglgt6vf5y.png","canonical_url":"https://dev.to/apostrophecms/using-s3-compatible-storage-solutions-with-apostrophecms-40c1","created_at":"2022-11-07T17:16:57Z","edited_at":"2022-11-07T17:50:04Z","crossposted_at":null,"published_at":"2022-11-07T17:47:45Z","last_comment_at":"2022-11-07T17:47:45Z","reading_time_minutes":7,"tag_list":"tutorial, webdev, opensource, aws","tags":["tutorial","webdev","opensource","aws"],"body_html":"<p>This tutorial details file storage solutions for FileBase, Vultr, Wasabi, and DigitalOcean using S3 API in order to deploy Apostrophe to production.</p>\n\n<p>Deploying Apostrophe to production requires that you specify hosting for the code base, the MongoDB instance, and storage for any uploaded content. Many hosting services can provide all three, but it is also possible and sometimes desirable to split these between different services. This tutorial looks at file storage solutions using the S3 API.</p>\n\n<h2>\n  <a name=\"what-is-the-s3-api\" href=\"#what-is-the-s3-api\">\n  </a>\n  What is the S3 API?\n</h2>\n\n<p>The S3 API is a REST API developed by Amazon as a means of communicating with their Simple Storage Service (S3). Versions of this API have since been adopted by many other providers. These alternative providers can sometimes provide lower cost points or desirable features, like IPFS. The <code>@apostrophecms/uploadfs</code> module provides an easy way to connect to most S3 API-powered services through environmental variables.</p>\n\n<p>Depending on the service used for hosting your code base, there are different ways to set these variables. For example, Heroku as we show in our <a href=\"https://v3.docs.apostrophecms.org/cookbook/deploying-to-heroku.html\">hosting tutorial</a>, allows you to configure your app either through their CLI or dashboard. For other hosting environments, you may need to set these variables through a <code>.env</code> or <code>.bashrc</code> file.</p>\n\n<p>Let's start by looking at how to connect with Amazon Web Services (AWS) S3.</p>\n\n<h2>\n  <a name=\"using-aws-s3-services\" href=\"#using-aws-s3-services\">\n  </a>\n  Using AWS S3 services\n</h2>\n\n<p>For AWS S3 we need to add values for four environment variables: <code>APOS_S3_BUCKET</code>, <code>APOS_S3_REGION</code>, <code>APOS_S3_KEY</code>, and <code>APOS_S3_SECRET</code>.</p>\n\n<ol>\n<li>Create an <a href=\"https://aws.amazon.com/pm/serv-s3/\">Amazon AWS</a> account and then log into the management console. From the \"Services\" menu select \"Storage\" and then \"S3\". Note that Amazon offers 12 months free with a fixed data cap.</li>\n<li>This should take you to a dashboard screen where you can create a new bucket. Give your bucket a name. This is what we will use as a value for the <code>APOS_S3_BUCKET</code> environment variable.</li>\n<li>Select an AWS region - this is the value we will use for the <code>APOS_S3_REGION</code> variable.</li>\n<li>Leave everything else alone for now. We will come back to security in the next section.</li>\n<li>From your account drop-down, select \"Security credentials\".</li>\n<li>Open the \"Access keys\" section.</li>\n<li>Click to \"Create New Access Key\"</li>\n<li>This will create both our <code>APOS_S3_KEY</code> and <code>APOS_S3_SECRET</code> values. Make sure to save your secret value. You will be able to see your key from this page, but not your secret.</li>\n</ol>\n\n<p>Setting these variables will allow for upload into your bucket, but until you change the permissions settings for the bucket your site won't be able to access the resources.</p>\n\n<h4>\n  <a name=\"example-amazon-s3-permissions\" href=\"#example-amazon-s3-permissions\">\n  </a>\n  Example Amazon S3 permissions\n</h4>\n\n<p>First, select the bucket from the S3 management console and then click on the \"Permissions\" tab. Click on the \"Edit\" button to edit your permissions.</p>\n\n<p><a href=\"https://res.cloudinary.com/practicaldev/image/fetch/s--HODquYXm--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/gdnaarlym5kx73beoedj.png\" class=\"article-body-image-wrapper\"><img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--HODquYXm--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/gdnaarlym5kx73beoedj.png\" alt=\"AWS s3 permissions tab\" loading=\"lazy\" width=\"880\" height=\"296\"></a></p>\n\n<p>Uncheck the \"Block all public access\" box and save the changes. You will have to confirm that you want to do this.</p>\n\n<p><a href=\"https://res.cloudinary.com/practicaldev/image/fetch/s--w-7I9pon--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ov8qwklq40gbxwwycjlo.png\" class=\"article-body-image-wrapper\"><img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--w-7I9pon--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ov8qwklq40gbxwwycjlo.png\" alt=\"Amazon s3 public permissions\" loading=\"lazy\" width=\"880\" height=\"668\"></a></p>\n\n<p>Scroll down the page to the \"Object Ownership\" section and click the \"Edit\" button.</p>\n\n<p><a href=\"https://res.cloudinary.com/practicaldev/image/fetch/s--vKTEFLHG--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/hl7uh84m95fqy6rmtg46.png\" class=\"article-body-image-wrapper\"><img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--vKTEFLHG--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/hl7uh84m95fqy6rmtg46.png\" alt=\"AWS s3 object ownership\" loading=\"lazy\" width=\"880\" height=\"121\"></a></p>\n\n<p>Select \"ACLs enabled\" and \"Object writer\" then acknowledge the warning and save the changes.</p>\n\n<p><a href=\"https://res.cloudinary.com/practicaldev/image/fetch/s--cI7PrX46--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7nhctnejc57rigo8fq7l.png\" class=\"article-body-image-wrapper\"><img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--cI7PrX46--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7nhctnejc57rigo8fq7l.png\" alt=\"Amazon s3 object permission\" loading=\"lazy\" width=\"880\" height=\"547\"></a></p>\n\n<h2>\n  <a name=\"using-filebase-for-storage\" href=\"#using-filebase-for-storage\">\n  </a>\n  Using FileBase for storage\n</h2>\n\n<p>The FileBase storage service uses a truncated version of the S3 API. However, we can use this service in almost the same manner as the AWS S3 service. In this case, we must pass in one additional environment variable, <code>APOS_S3_ENDPOINT</code>, and not set the <code>APOS_S3_REGION</code> variable.</p>\n\n<ol>\n<li>Create a <a href=\"https://filebase.com/\">FileBase account</a>. While the service does have a free tier, it doesn't allow public access. This means our site won't be able to load resources, so you need to select one of their paid plans.</li>\n<li>From the console switch to the \"Buckets\" tab and click on \"Create Bucket\".</li>\n<li>Give the bucket a name. This is the value we will pass to the <code>APOS_S3_BUCKET</code> variable.</li>\n<li>Leave the storage network as \"IPFS\" and click \"Create Bucket\".</li>\n<li>Set the bucket access to public using the toggle next to the bucket name.</li>\n<li>Click the \"Access Keys\" tab.</li>\n<li>This screen will display the key and secret values we will add to the <code>APOS_S3_KEY</code> and <code>APOS_S3_SECRET</code> variables.</li>\n<li>On this screen we can also get the value for the <code>APOS_S3_ENDPOINT</code> environment variable from the URL listed under 'S3 API Endpoint'. Note: you should not set the <code>APOS_S3_REGION</code> key.</li>\n</ol>\n\n<h4>\n  <a name=\"filebase-security\" href=\"#filebase-security\">\n  </a>\n  FileBase Security\n</h4>\n\n<p>While FileBase can accept the same type of CORS (cross-origin resource sharing) and ACL (access control list) rules as AWS S3, simply setting the security toggle to \"public\" on the \"Buckets\" screen should be enough for most sites.</p>\n\n<h2>\n  <a name=\"using-vultr-for-storage\" href=\"#using-vultr-for-storage\">\n  </a>\n  Using Vultr for storage\n</h2>\n\n<p>The Vultr storage service uses a truncated version of the S3 API. However, we can use this service in almost the same manner as the AWS S3 service. In this case, we must pass in one additional environment variable, <code>APOS_S3_ENDPOINT</code>, and not set the <code>APOS_S3_REGION</code> variable.</p>\n\n<ol>\n<li>Create a <a href=\"https://www.vultr.com/\">Vultr account</a>. While the service doesn't have a free tier, you should be able to find a free credit offer if you are a new customer.</li>\n<li>Log in to your account and navigate to \"Products\".</li>\n<li>Select \"Objects\" to begin creating a new storage object.</li>\n<li>Select your preferred location.</li>\n<li>Add a label for your object - this object can contain multiple storage buckets.</li>\n<li>Wait for the object to install and then click on the green arrow.</li>\n<li>Under the S3 Credentials you will see your Hostname, Secret Key, and Access Key. These will be used for the <code>APOS_S3_ENDPOINT</code>, <code>APOS_S3_SECRET</code>, and <code>APOS_S3_KEY</code> variables. Note: you should not set the <code>APOS_S3_REGION</code> key.</li>\n<li>Click the \"Buckets\" tab.</li>\n<li>Click the \"Create Bucket\" button.</li>\n<li>Add a bucket name following the noted limitations. This name will be used to set the <code>APOS_S3_BUCKET</code> variable.</li>\n</ol>\n\n<h4>\n  <a name=\"vultr-security\" href=\"#vultr-security\">\n  </a>\n  Vultr Security\n</h4>\n\n<p>While files uploaded to Vultr are private by default, the <code>@apostrophecms/uploadfs</code> module sets <code>bucketObjectsACL</code> to <code>public-read</code> by default. Therefore, you don't have to perform any further security changes in order for your site to be able to access the stored files.</p>\n\n<h2>\n  <a name=\"using-wasabi-for-storage\" href=\"#using-wasabi-for-storage\">\n  </a>\n  Using Wasabi for storage\n</h2>\n\n<p>The Wasabi storage service has an expanded API that supports some features not found in the AWS S3 REST API, but is compatible with the core S3 API that Apostrophe uses. We can use this service in almost the same manner as the AWS S3 service. In this case, we must pass in one additional environment variable, <code>APOS_S3_ENDPOINT</code>, and not set the <code>APOS_S3_REGION</code> variable.</p>\n\n<ol>\n<li>Create a <a href=\"https://www.wasabi.com/\">Wasabi account</a>. While the service does have a free tier, it doesn't allow public access. This means our site won't be able to load resources, so you need to select one of their paid plans. You may be able to find a credit offer if you are a new customer.</li>\n<li>Once logged in, click on \"Create Bucket\".</li>\n<li>Add a bucket name. This is the value we need to set for the <code>APOS_S3_BUCKET</code> variable.</li>\n<li>Select a preferred region. Note the URL to the right of each region. This is the value for the <code>APOS_S3_ENDPOINT</code> variable. Although each bucket will have a region listed, this should not be added to the <code>APOS_S3_REGION</code> variable. This variable should not be set.</li>\n<li>Click the \"Next\" button to step through the settings until the \"Create bucket\" button comes up. Nothing needs to be changed.</li>\n<li>Click on the \"Access Keys\" menu item on the left.</li>\n<li>Click the \"Create new access key\" button.</li>\n<li>Download the credentials. You won't be able to get the secret again.</li>\n<li>Get the <code>APOS_S3_SECRET</code> and <code>APOS_S3_KEY</code> values from the file.</li>\n</ol>\n\n<p>If you didn't note the endpoint URL you can get it based on the region code (e.g. 'us-east-1') from this <a href=\"https://wasabi-support.zendesk.com/hc/en-us/articles/360015106031-What-are-the-service-URLs-for-Wasabi-s-different-storage-regions-\">page</a>.</p>\n\n<h4>\n  <a name=\"wasabi-security\" href=\"#wasabi-security\">\n  </a>\n  Wasabi security\n</h4>\n\n<p>The files uploaded to the Wasabi bucket are publicly available right away without the need for any changes. However, if you click the menu to the right of the bucket name and select \"Setting\", it will bring up a page that allows you to alter permissions easily.</p>\n\n<h2>\n  <a name=\"using-digitalocean-spaces-for-storage\" href=\"#using-digitalocean-spaces-for-storage\">\n  </a>\n  Using DigitalOcean Spaces for storage\n</h2>\n\n<p>The DigitalOcean Spaces API is a truncated version of the AWS S3 API that supports all the features we need for using it for storage with Apostrophe. We can use this service in almost the same manner as the AWS S3 service. In this case, we must pass in one additional environment variable, <code>APOS_S3_ENDPOINT</code>, and not set the <code>APOS_S3_REGION</code> variable.</p>\n\n<ol>\n<li>Create a <a href=\"https://www.digitalocean.com/\">DigitalOcean account</a>. They don't have a free tier, but do offer a credit to new customers.</li>\n<li>Once logged in, you'll be brought to a project page. Click on \"Store static objects\". In some cases, you might instead have to click \"Start using Spaces\".</li>\n<li>Choose a preferred datacenter region.</li>\n<li>Leave \"Restrict File Listing\" selected.</li>\n<li>Create a name and select a project. If you haven't made one it will assign it to a default called \"first-project\". The name is the value for the <code>APOS_S3_BUCKET</code> variable.</li>\n<li>Click on \"Create a Space\".</li>\n<li>Click on the \"Settings\" tab.</li>\n<li>Copy the \"endpoint\" URL. This is the value for the <code>APOS_S3_ENDPOINT</code> variable.</li>\n<li>Click on the \"API\" tab in the left menu.</li>\n<li>Scroll down to the \"Spaces access keys\" section and click \"Generate New Key\".</li>\n<li>Add a name and hit return. It will take a few seconds to generate the key and secret. Copy them. You will be able to get the key again by returning to this page, but you won't be able to retrieve the secret.</li>\n<li>Assign the key and secret values to the <code>APOS_S3_KEY</code> and <code>APOS_S3_SECRET</code> variables, respectively. The <code>APOS_S3_REGION</code> variable should not be set.</li>\n</ol>\n\n<h4>\n  <a name=\"digitalocean-security\" href=\"#digitalocean-security\">\n  </a>\n  DigitalOcean Security\n</h4>\n\n<p>The assets uploaded to the DigitalOcean Spaces are publicly readable by default. No security policy changes are required. If needed, you can configure the CORS (cross-origin resource sharing) through the settings of each space, and you shouldn't need to change anything.</p>\n\n<h4>\n  <a name=\"share-your-solution\" href=\"#share-your-solution\">\n  </a>\n  Share your Solution\n</h4>\n\n<p>Have you implemented any of the described solutions? Share your experience with the author in <a href=\"http://chat.apostrophecms.org/\">Discord</a>. </p>\n\n","body_markdown":"This tutorial details file storage solutions for FileBase, Vultr, Wasabi, and DigitalOcean using S3 API in order to deploy Apostrophe to production.\n\nDeploying Apostrophe to production requires that you specify hosting for the code base, the MongoDB instance, and storage for any uploaded content. Many hosting services can provide all three, but it is also possible and sometimes desirable to split these between different services. This tutorial looks at file storage solutions using the S3 API.\n\n##What is the S3 API?\nThe S3 API is a REST API developed by Amazon as a means of communicating with their Simple Storage Service (S3). Versions of this API have since been adopted by many other providers. These alternative providers can sometimes provide lower cost points or desirable features, like IPFS. The `@apostrophecms/uploadfs` module provides an easy way to connect to most S3 API-powered services through environmental variables.\n\nDepending on the service used for hosting your code base, there are different ways to set these variables. For example, Heroku as we show in our [hosting tutorial] (https://v3.docs.apostrophecms.org/cookbook/deploying-to-heroku.html), allows you to configure your app either through their CLI or dashboard. For other hosting environments, you may need to set these variables through a `.env` or `.bashrc` file.\n\nLet's start by looking at how to connect with Amazon Web Services (AWS) S3.\n\n##Using AWS S3 services\nFor AWS S3 we need to add values for four environment variables: `APOS_S3_BUCKET`, `APOS_S3_REGION`, `APOS_S3_KEY`, and `APOS_S3_SECRET`.\n\n1. Create an [Amazon AWS] (https://aws.amazon.com/pm/serv-s3/) account and then log into the management console. From the \"Services\" menu select \"Storage\" and then \"S3\". Note that Amazon offers 12 months free with a fixed data cap.\n2. This should take you to a dashboard screen where you can create a new bucket. Give your bucket a name. This is what we will use as a value for the `APOS_S3_BUCKET` environment variable.\n3. Select an AWS region - this is the value we will use for the `APOS_S3_REGION` variable.\n4. Leave everything else alone for now. We will come back to security in the next section.\n5. From your account drop-down, select \"Security credentials\".\n6. Open the \"Access keys\" section.\n7. Click to \"Create New Access Key\"\n8. This will create both our `APOS_S3_KEY` and `APOS_S3_SECRET` values. Make sure to save your secret value. You will be able to see your key from this page, but not your secret.\n\nSetting these variables will allow for upload into your bucket, but until you change the permissions settings for the bucket your site won't be able to access the resources.\n\n####Example Amazon S3 permissions\nFirst, select the bucket from the S3 management console and then click on the \"Permissions\" tab. Click on the \"Edit\" button to edit your permissions.\n\n\n![AWS s3 permissions tab](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/gdnaarlym5kx73beoedj.png)\n\n\nUncheck the \"Block all public access\" box and save the changes. You will have to confirm that you want to do this.\n\n\n![Amazon s3 public permissions](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ov8qwklq40gbxwwycjlo.png)\n\n\nScroll down the page to the \"Object Ownership\" section and click the \"Edit\" button.\n\n\n![AWS s3 object ownership](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/hl7uh84m95fqy6rmtg46.png)\n\n\nSelect \"ACLs enabled\" and \"Object writer\" then acknowledge the warning and save the changes.\n\n\n![Amazon s3 object permission](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7nhctnejc57rigo8fq7l.png)\n\n\n##Using FileBase for storage\nThe FileBase storage service uses a truncated version of the S3 API. However, we can use this service in almost the same manner as the AWS S3 service. In this case, we must pass in one additional environment variable, `APOS_S3_ENDPOINT`, and not set the `APOS_S3_REGION` variable.\n\n1. Create a [FileBase account] (https://filebase.com/). While the service does have a free tier, it doesn't allow public access. This means our site won't be able to load resources, so you need to select one of their paid plans.\n2. From the console switch to the \"Buckets\" tab and click on \"Create Bucket\".\n3. Give the bucket a name. This is the value we will pass to the `APOS_S3_BUCKET` variable.\n4. Leave the storage network as \"IPFS\" and click \"Create Bucket\".\n5. Set the bucket access to public using the toggle next to the bucket name.\n6. Click the \"Access Keys\" tab.\n7. This screen will display the key and secret values we will add to the `APOS_S3_KEY` and `APOS_S3_SECRET` variables.\n8. On this screen we can also get the value for the `APOS_S3_ENDPOINT` environment variable from the URL listed under 'S3 API Endpoint'. Note: you should not set the `APOS_S3_REGION` key.\n\n####FileBase Security\nWhile FileBase can accept the same type of CORS (cross-origin resource sharing) and ACL (access control list) rules as AWS S3, simply setting the security toggle to \"public\" on the \"Buckets\" screen should be enough for most sites.\n\n##Using Vultr for storage\nThe Vultr storage service uses a truncated version of the S3 API. However, we can use this service in almost the same manner as the AWS S3 service. In this case, we must pass in one additional environment variable, `APOS_S3_ENDPOINT`, and not set the `APOS_S3_REGION` variable.\n\n1. Create a [Vultr account] (https://www.vultr.com/). While the service doesn't have a free tier, you should be able to find a free credit offer if you are a new customer.\n2. Log in to your account and navigate to \"Products\".\n3. Select \"Objects\" to begin creating a new storage object.\n4. Select your preferred location.\n5. Add a label for your object - this object can contain multiple storage buckets.\n6. Wait for the object to install and then click on the green arrow.\n7. Under the S3 Credentials you will see your Hostname, Secret Key, and Access Key. These will be used for the `APOS_S3_ENDPOINT`, `APOS_S3_SECRET`, and `APOS_S3_KEY` variables. Note: you should not set the `APOS_S3_REGION` key.\n8. Click the \"Buckets\" tab.\n9. Click the \"Create Bucket\" button.\n10. Add a bucket name following the noted limitations. This name will be used to set the `APOS_S3_BUCKET` variable.\n\n####Vultr Security\nWhile files uploaded to Vultr are private by default, the `@apostrophecms/uploadfs` module sets `bucketObjectsACL` to `public-read` by default. Therefore, you don't have to perform any further security changes in order for your site to be able to access the stored files.\n\n##Using Wasabi for storage\nThe Wasabi storage service has an expanded API that supports some features not found in the AWS S3 REST API, but is compatible with the core S3 API that Apostrophe uses. We can use this service in almost the same manner as the AWS S3 service. In this case, we must pass in one additional environment variable, `APOS_S3_ENDPOINT`, and not set the `APOS_S3_REGION` variable.\n\n1. Create a [Wasabi account] (https://www.wasabi.com/). While the service does have a free tier, it doesn't allow public access. This means our site won't be able to load resources, so you need to select one of their paid plans. You may be able to find a credit offer if you are a new customer.\n2. Once logged in, click on \"Create Bucket\".\n3. Add a bucket name. This is the value we need to set for the `APOS_S3_BUCKET` variable.\n4. Select a preferred region. Note the URL to the right of each region. This is the value for the `APOS_S3_ENDPOINT` variable. Although each bucket will have a region listed, this should not be added to the `APOS_S3_REGION` variable. This variable should not be set.\n5. Click the \"Next\" button to step through the settings until the \"Create bucket\" button comes up. Nothing needs to be changed.\n6. Click on the \"Access Keys\" menu item on the left.\n7. Click the \"Create new access key\" button.\n8. Download the credentials. You won't be able to get the secret again.\n9. Get the `APOS_S3_SECRET` and `APOS_S3_KEY` values from the file.\n\nIf you didn't note the endpoint URL you can get it based on the region code (e.g. 'us-east-1') from this [page] (https://wasabi-support.zendesk.com/hc/en-us/articles/360015106031-What-are-the-service-URLs-for-Wasabi-s-different-storage-regions-).\n\n####Wasabi security\nThe files uploaded to the Wasabi bucket are publicly available right away without the need for any changes. However, if you click the menu to the right of the bucket name and select \"Setting\", it will bring up a page that allows you to alter permissions easily.\n\n##Using DigitalOcean Spaces for storage\nThe DigitalOcean Spaces API is a truncated version of the AWS S3 API that supports all the features we need for using it for storage with Apostrophe. We can use this service in almost the same manner as the AWS S3 service. In this case, we must pass in one additional environment variable, `APOS_S3_ENDPOINT`, and not set the `APOS_S3_REGION` variable.\n\n1. Create a [DigitalOcean account] (https://www.digitalocean.com/). They don't have a free tier, but do offer a credit to new customers.\n2. Once logged in, you'll be brought to a project page. Click on \"Store static objects\". In some cases, you might instead have to click \"Start using Spaces\".\n3. Choose a preferred datacenter region.\n4. Leave \"Restrict File Listing\" selected.\n5. Create a name and select a project. If you haven't made one it will assign it to a default called \"first-project\". The name is the value for the `APOS_S3_BUCKET` variable.\n6. Click on \"Create a Space\".\n7. Click on the \"Settings\" tab.\n8. Copy the \"endpoint\" URL. This is the value for the `APOS_S3_ENDPOINT` variable.\n9. Click on the \"API\" tab in the left menu.\n10. Scroll down to the \"Spaces access keys\" section and click \"Generate New Key\".\n11. Add a name and hit return. It will take a few seconds to generate the key and secret. Copy them. You will be able to get the key again by returning to this page, but you won't be able to retrieve the secret.\n12. Assign the key and secret values to the `APOS_S3_KEY` and `APOS_S3_SECRET` variables, respectively. The `APOS_S3_REGION` variable should not be set.\n\n####DigitalOcean Security\nThe assets uploaded to the DigitalOcean Spaces are publicly readable by default. No security policy changes are required. If needed, you can configure the CORS (cross-origin resource sharing) through the settings of each space, and you shouldn't need to change anything.\n\n####Share your Solution\nHave you implemented any of the described solutions? Share your experience with the author in [Discord] (http://chat.apostrophecms.org/). ","user":{"name":"Apostrophe","username":"apostrophecms","twitter_username":"apostrophecms","github_username":null,"user_id":478278,"website_url":"https://apostrophecms.com","profile_image":"https://res.cloudinary.com/practicaldev/image/fetch/s--IrtxM_ZY--/c_fill,f_auto,fl_progressive,h_640,q_auto,w_640/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/478278/1e7d222d-875f-49f9-8801-3508ab3d62f3.png","profile_image_90":"https://res.cloudinary.com/practicaldev/image/fetch/s--KIxcwLhQ--/c_fill,f_auto,fl_progressive,h_90,q_auto,w_90/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/478278/1e7d222d-875f-49f9-8801-3508ab3d62f3.png"}}